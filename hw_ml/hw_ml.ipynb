{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('anna.txt', encoding='utf-8') as f:\n",
    "    anna = f.read()\n",
    "with open('sonets.txt', encoding='utf-8') as f:\n",
    "    sonets = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anna_sentences = re.split(r'(?:[.]\\s*){3}|[.?!]', anna)\n",
    "sonet_sentences = re.split(r'(?:[.]\\s*){3}|[.?!]', sonets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на длину выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378 21499\n"
     ]
    }
   ],
   "source": [
    "print(len(sonet_sentences), len(anna_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Она очень неровная, поэтому сделаем их одинаковыми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anna_sentences = random.sample(anna_sentences, len(sonet_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378 1378\n"
     ]
    }
   ],
   "source": [
    "print(len(sonet_sentences), len(anna_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anna_sent_letters = [len([char for char in sent if char.isalpha()]) for sent in anna_sentences]\n",
    "sonet_sent_letters = [len([char for char in sent if char.isalpha()]) for sent in sonet_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anna_unique_letters = [len(set([char for char in sent if char.isalpha()])) for sent in anna_sentences]\n",
    "sonet_unique_letters = [len(set([char for char in sent if char.isalpha()])) for sent in sonet_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vowels = 'аоэуыяёеюи'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anna_sent_vowels = [len([char for char in sent if char in vowels]) for sent in anna_sentences]\n",
    "sonet_sent_vowels = [len([char for char in sent if char in vowels]) for sent in sonet_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lenwords(sentence):\n",
    "    return [len(word) for word in sentence.split()] or [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anna_sentlens = [lenwords(sentence) for sentence in anna_sentences]\n",
    "sonet_sentlens = [lenwords(sentence) for sentence in sonet_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anna_word_letters_median = [np.median(sent) for sent in anna_sentlens]\n",
    "sonet_word_letters_median = [np.median(sent) for sent in sonet_sentlens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lenwords_vow(sentence):\n",
    "    return [len([char for char in word if char in vowels]) for word in sentence.split()] or [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anna_sentlens_vow = [lenwords_vow(sentence) for sentence in anna_sentences]\n",
    "sonet_sentlens_vow = [lenwords_vow(sentence) for sentence in sonet_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anna_word_vowels_median = [np.median(sent) for sent in anna_sentlens_vow]\n",
    "sonet_word_vowels_median = [np.median(sent) for sent in sonet_sentlens_vow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем вектора в кучу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('sent_letters', anna_sent_letters + sonet_sent_letters),\n",
    "    ('sent_letters_unique', anna_unique_letters + sonet_unique_letters),\n",
    "    ('sent_vowels', anna_sent_vowels + sonet_sent_vowels),\n",
    "    ('word_letters_median', anna_word_letters_median + sonet_word_letters_median),\n",
    "    ('word_vowels_median', anna_word_vowels_median + sonet_word_vowels_median),\n",
    "    ('class', [0 for _ in range(len(anna_sent_letters))] + [1 for _ in range(len(sonet_sent_letters))])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_items(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = df.loc[:,['sent_letters','sent_letters_unique', 'sent_vowels', 'word_letters_median', 'word_vowels_median']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим на трейн и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, df['class'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем для начала байеса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.559782608696 0.636771300448\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "a = accuracy_score(y_test, y_pred)\n",
    "f = f1_score(y_test, y_pred)\n",
    "print(a, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат не оч, попробуем рендом форест и логит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76268115942 0.749521988528\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "a = accuracy_score(y_test, y_pred)\n",
    "f = f1_score(y_test, y_pred)\n",
    "print(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748188405797 0.745886654479\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "a = accuracy_score(y_test, y_pred)\n",
    "f = f1_score(y_test, y_pred)\n",
    "print(a, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже лучше"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
